# NLP-PoetryModels
From RNN to GRU and LSTM: A Study on the Performance of Poem Generation Models Integrating Bidirectional and Attention Techniques

- [ç®€ä½“ä¸­æ–‡](./docs/README-cn.md)
- [English](./README.md)

<div align="center">

## From RNN to GRU and LSTM: A Study on the Performance of Poem Generation Models Integrating Bidirectional and Attention Techniques
[ğŸ“„[Document](https://github.com/ffengc/NLP-PoetryModels/blob/main/README.md)] &emsp; [ğŸ’»[Platform](https://www.tensorflow.org)] &emsp; <br>
[ğŸŒ…[Code](https://github.com/ffengc/NLP-PoetryModels/)] &emsp; [ğŸ“–[Article(comming soon)](https://github.com/ffengc/NLP-PoetryModels/docs/article.pdf)] &emsp;<br>


</div>

***

- [NLP-PoetryModels](#nlp-poetrymodels)
  - [From RNN to GRU and LSTM: A Study on the Performance of Poem Generation Models Integrating Bidirectional and Attention Techniques](#from-rnn-to-gru-and-lstm-a-study-on-the-performance-of-poem-generation-models-integrating-bidirectional-and-attention-techniques)
  - [Abstract](#abstract)
  - [Environment Setup and how to run this project](#environment-setup-and-how-to-run-this-project)
  - [Model Structure](#model-structure)
  - [Training Results](#training-results)
  - [Chinese Poem Generation Quality Assessment](#chinese-poem-generation-quality-assessment)
    - [BERT-CCPoem](#bert-ccpoem)
    - [Manual Evaluation Rules](#manual-evaluation-rules)
  - [Test Results](#test-results)
  - [Result Generation Examples](#result-generation-examples)
  - [Citations](#citations)

***

## Abstract

By delving deep into the poem generation model CharRNN, we experimented with three core modules: LSTM, RNN, and GRU, and introduced variants of the attention mechanism and bidirectional network structure. Experiments involved multiple datasets, including Chinese poems, English articles, Chinese song lyrics, Japanese articles, and Linux script languages, with the Chinese poem dataset utilizing all model variants, while other datasets were trained using only the LSTM model. The effects were tested using Tsinghua University's AI Institute's NLP and Society and Humanities Computing Research Center's BERT-CCPoem automatic evaluation system and manual scoring method. Results show that the basic LSTM and GRU models performed well in the poem generation task, while the introduced attention mechanism and bidirectional structure reduced training efficiency and increased loss, but did not show significant improvement in the quality of generated poems. The findings of this study provide new perspectives and empirical bases for the application of deep learning in the field of artistic creation.

## Environment Setup and how to run this project

- **[run.md](./docs/run-en.md)**

## Model Structure

![](./assets/model.png)

## Training Results

![](./assets/train.png)

## Chinese Poem Generation Quality Assessment

Details can be found in the article.

### BERT-CCPoem

cite from: [https://github.com/THUNLP-AIPoet/BERT-CCPoem](https://github.com/THUNLP-AIPoet/BERT-CCPoem)

The BERT_CCPoem model is based on the BERT architecture, specifically optimized for the semantic understanding of Chinese classical poetry texts. BERT's bidirectional training mechanism allows the model to consider the information before and after a word when representing it, thereby obtaining a richer and more accurate semantic representation of each word. This deep bidirectional representation is essential for understanding poetry, a text form with complex structure and rich semantics, as the language of poetry often contains multiple layers of imagery and metaphors.

### Manual Evaluation Rules

In assessing the performance of the poem generation models, a manual evaluation method was used, setting three main indicators (all with a maximum score of 5 points): grammatical correctness, clarity of expression, and thematic coherence. Grammatical correctness mainly assesses whether the structure and word count of the poem are aligned, accounting for 0.6 of the total score. Clarity of expression assesses whether readers can clearly understand the meaning of the verses, accounting for 0.25 of the total score. Thematic coherence checks whether the theme of the entire poem is consistent, accounting for 0.15 of the total score. These three indicators collectively determine the overall quality of the poems generated by the model.

<div align="center">

| Evaluation Indicator | Weight |
|-------|-------|
| Grammatical Correctness | 0.60 |
| Clarity of Expression | 0.25 |
| Thematic Coherence | 0.15 |

</div>

The final score consists of 50% machine scoring and 50% manual scoring.

## Test Results

<div align="center">

| Model                  | Score (out of 100) |
|----------------------|-----------------|
| `lstm`               | 92.59           |
| `lstm+attention`     | 58.88           |
| `bi-lstm`            | 51.30           |
| `bi-lstm+attention`  | 58.68           |
| `rnn`                | 96.90           |
| `rnn+attention`      | 77.70           |
| `bi-rnn`             | 26.00           |
| `bi-rnn+attention`   | 29.41           |
| `gru`                | 98.41           |
| `gru+attention`      | 17.70           |
| `bi-gru`             | 32.80           |
| `bi-gru+attention`   | 26.00           |

</div>

**Best Performing GRU Model:** The standalone GRU model scored the highest at 98.41 points. This indicates that the GRU structure is very effective for this specific poem generation task.

**RNN Also Performs Well:** The pure RNN model scored the second highest at 96.90 points, demonstrating the powerful capability of RNNs in handling text generation tasks.

**LSTM Scores High but Unstable:** The LSTM model itself performed well with a score of 92.59. However, when the attention mechanism was added, the score significantly dropped to 58.88.

**Most Models Score Lower with Added Attention Mechanism:** Except for RNN, most models scored lower after the addition of the attention mechanism. Especially for the GRU model, the score plummeted from 98.41 to 17.70 after adding attention.

**Bidirectional Models Perform Poorly:** All bidirectional models (bi-LSTM, bi-RNN, bi-GRU) scored generally low, mostly below 30, regardless of whether attention was added. This may indicate that the bidirectional structure may not be the optimal choice for this type of generation task.

**Summary:** Simple GRU and RNN models demonstrated high effectiveness in this poetry generation task, while bidirectional structures and models with added attention generally performed poorly. This information can guide future model selection and optimization.

## Result Generation Examples

cite from: [https://github.com/wandouduoduo/SunRnn](https://github.com/wandouduoduo/SunRnn)

Generate English articles:

```
BROTON:
When thou art at to she we stood those to that hath
think they treaching heart to my horse, and as some trousting.

LAUNCE:
The formity so mistalied on his, thou hast she was
to her hears, what we shall be that say a soun man
Would the lord and all a fouls and too, the say,
That we destent and here with my peace.

PALINA:
Why, are the must thou art breath or thy saming,
I have sate it him with too to have me of
I the camples.
```

Generate Chinese poems:

```
ä½•äººæ— ä¸è§ï¼Œæ­¤åœ°è‡ªä½•å¦‚ã€‚
ä¸€å¤œå±±è¾¹å»ï¼Œæ±Ÿå±±ä¸€å¤œå½’ã€‚
å±±é£æ˜¥è‰è‰²ï¼Œç§‹æ°´å¤œå£°æ·±ã€‚
ä½•äº‹åŒç›¸è§ï¼Œåº”çŸ¥æ—§å­äººã€‚
ä½•å½“ä¸ç›¸è§ï¼Œä½•å¤„è§æ±Ÿè¾¹ã€‚
ä¸€å¶ç”Ÿäº‘é‡Œï¼Œæ˜¥é£å‡ºç«¹å ‚ã€‚
ä½•æ—¶æœ‰ç›¸è®¿ï¼Œä¸å¾—åœ¨å›å¿ƒã€‚
```

Generate Chinese articles:

```
é—»è¨€ï¼Œè§ç‚ä¸€æ€”ï¼Œæ—‹å³ç›®å…‰è½¬å‘ä¸€æ—çš„é‚£åç°è¢é’å¹´ï¼Œç„¶åç›®å…‰åœ¨é‚£ä½è€è€…èº«ä¸Šæ‰«è¿‡ï¼Œé‚£é‡Œï¼Œä¸€ä¸ªå·¨å¤§çš„çŸ³å°ä¸Šï¼Œæœ‰ç€ä¸€ä¸ªå·¨å¤§çš„å·¨å‘ï¼Œä¸€äº›é»‘è‰²å…‰æŸ±ï¼Œæ­£åœ¨ä»ä¸­ï¼Œä¸€é“å·¨å¤§çš„é»‘è‰²å·¨èŸ’ï¼Œä¸€è‚¡æåº¦ææ€–çš„æ°”æ¯ï¼Œä»å¤©ç©ºä¸Šæš´å°„è€Œå‡º ï¼Œç„¶ååœ¨å…¶ä¸­ä¸€äº›ä¸€é“é“ç›®å…‰ä¸­ï¼Œé—ªç”µèˆ¬çš„å‡ºç°åœ¨äº†é‚£äº›äººå½±ï¼Œåœ¨é‚£ç§çµé­‚ä¹‹ä¸­ï¼Œå´æ˜¯æœ‰ç€è®¸äº›å¼ºè€…çš„æ„Ÿè§‰ï¼Œåœ¨ä»–ä»¬é¢å‰ï¼Œé‚£ä¸€é“é“èº«å½±ï¼Œå´æ˜¯å¦‚åŒä¸€é“é»‘å½±ä¸€èˆ¬ï¼Œåœ¨é‚£ä¸€é“é“ç›®å…‰ä¸­ï¼Œåœ¨è¿™ç‰‡å¤©åœ°é—´ï¼Œåœ¨é‚£å·¨å¤§çš„ç©ºé—´ä¸­ï¼Œå¼¥æ¼«è€Œå¼€â€¦â€¦

â€œè¿™æ˜¯ä¸€ä½æ–—å°Šé˜¶åˆ«ï¼Œä¸è¿‡ä¸ç®¡ä½ ï¼Œä¹Ÿä¸å¯èƒ½ä¼šå‡ºæ‰‹ï¼Œé‚£äº›å®¶ä¼™ï¼Œå¯ä»¥ä¸ºäº†è¿™é‡Œï¼Œè¿™é‡Œä¹Ÿæ˜¯èƒ½å¤Ÿæœ‰ç€ä¸€äº›å¼‚å¸¸ï¼Œè€Œä¸”ä»–ï¼Œä¹Ÿæ˜¯ä¸èƒ½å°†å…¶ä»–äººç»™ä½ çš„çµé­‚ï¼Œæ‰€ä»¥ï¼Œè¿™äº›äº‹ï¼Œæˆ‘ä¹Ÿæ˜¯ä¸å¯èƒ½å°†è¿™ä¸€ä¸ªäººçš„å¼ºè€…ç»™åå¤©èŸ’ï¼Œè¿™èˆ¬ä¸€æ¬¡ï¼Œæˆ‘ä»¬çš„å®åŠ›ï¼Œä¾¿æ˜¯èƒ½å¤Ÿå°†ä¹‹å‡»æ€â€¦â€¦â€

â€œè¿™é‡Œçš„äººï¼Œä¹Ÿæ˜¯èƒ½å¤Ÿä¸é­‚æ®¿å¼ºè€…æŠ—è¡¡ã€‚â€

è§ç‚çœ¼çœ¸ä¸­ä¹Ÿæ˜¯æ è¿‡ä¸€æŠ¹æƒŠéª‡ï¼Œæ—‹å³ä¸€ç¬‘ï¼Œæ—‹å³ä¸€å£°å†·å–ï¼Œèº«åé‚£äº›é­‚æ®¿æ®¿ä¸»ä¾¿æ˜¯å¯¹äºè§ç‚ï¼Œä¸€é“å†·å–çš„èº«ä½“ï¼Œåœ¨å¤©ç©ºä¹‹ä¸Šæš´å°„è€Œå‡ºï¼Œä¸€è‚¡ææ€–çš„åŠ²æ°”ï¼Œä¾¿æ˜¯ä»å¤©ç©ºå€¾æ´’è€Œä¸‹ã€‚

â€œå—¤ï¼â€
```

Generate Chinese song lyrics:

```
æˆ‘çŸ¥é“
æˆ‘çš„ä¸–ç•Œ ä¸€ç§è§£
æˆ‘ä¸€ç›´å®ç° è¯­ä¸æ˜¯æˆ‘
æœ‰ä»€ä¹ˆ(å®¢) æˆ‘åªæ˜¯ä¸€å£
æˆ‘æƒ³æƒ³æˆ‘ä¸æ¥ ä½ çš„å¾®ç¬‘
æˆ‘è¯´ ä½ æˆ‘ä½ çš„ä½ 
åªèƒ½æœ‰æˆ‘ ä¸€ä¸ªæ¢¦çš„
æˆ‘è¯´çš„æˆ‘çš„
æˆ‘ä¸èƒ½å†æƒ³
æˆ‘çš„çˆ±çš„æ‰‹ ä¸€ç‚¹æœ‰ç¾
æˆ‘ä»¬ ä½ çš„æˆ‘ ä½ ä¸ä¼šå†ä¼šçˆ±ä¸åˆ°
```

Generate code:

```
static int test_trace_task(struct rq *rq)
{
        read_user_cur_task(state);
        return trace_seq;
}

static int page_cpus(struct flags *str)
{
        int rc;
        struct rq *do_init;
};

/*
 * Core_trace_periods the time in is is that supsed,
 */
#endif

/*
 * Intendifint to state anded.
 */
int print_init(struct priority *rt)
{       /* Comment sighind if see task so and the sections */
        console(string, &can);
}
```

Generate Japanese articles:

```
ã€Œã‚ã‚ã€ãã‚Œã ã€ã€ã¨ãŠå¤ã¯ã€ã¨å¤ã®ãã®ã€
ã€Œãã†ã ã£ã¦ã„ã‚‹ã¨ã€ãŠå¤ã¯ã€ã“ã®ãŠå¤ãŒã€ãã®æ™‚ã€
ï¼ˆã‚ã€ã€
ã€€ã¨å£°ã«ã¯ãŠå¤ãŒã€ã“ã‚Œã¯ã€ã“ã®è†ã®æ–¹ã‚’å¼•å¯„ã£ã¦ã€ãŠå¤ã«ã€
ã€Œã¾ã‚ã€‚ã€ã¨ã€ãã®æ™‚ã®ãŠåº‡ã€ŠãŠã‚‚ã€‹ãªãŒã‚‰ã€
```

## Citations

**BERT-CCPoem: [https://github.com/THUNLP-AIPoet/BERT-CCPoem](https://github.com/THUNLP-AIPoet/BERT-CCPoem)**

**SunRnn: [https://github.com/wandouduoduo/SunRnn](https://github.com/wandouduoduo/SunRnn)** Part of my code structure comes from this repository.
